{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alison's approach to regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRoss-Industry Standard Process for Data Mining (CRISP-DM)\n",
    "\n",
    "Before we dig into the problem, lets refresh our memories on the steps in the CRISP-DM model.\n",
    "\n",
    "<img src=\"img/new_crisp-dm.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "\n",
    "<img src=\"img/grocery-cart.jpg\" width=\"500\">\n",
    "\n",
    "The data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities.\n",
    "\n",
    "The data is located in the csv called `big_mart.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously explored the features of the big_mart dataset but now BigMart wants us to answer the following question:\n",
    "\n",
    "**The sales team at BigMart wants to know which products have high sales.  They ask you to help them  predict if sales of each product at a particular store will be high or low using the big_mart dataset.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Understanding\n",
    "\n",
    "We have already done a great deal of exploratory data analysis of this dataset.  Let's refresh out memory on what the original data contained. \n",
    "\n",
    "<img src=\"img/big_mart_data_variables.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Preparation\n",
    "\n",
    "This step has already been done for you.  The following steps were taken and are reflected in the `big_mart_clean.csv` file.\n",
    "\n",
    "- Imputed missing values for `Outlet_Size` (replaced missing with the mode)\n",
    "- Imputed missing values for `Item_Weight` (replaced missing with the average)\n",
    "- Cleaned typos in `Item_Fat_Content`\n",
    "- Created new variable `Item_Type_Combined` (labels items as food, non-consumable, or drinks)\n",
    "- Created new variable `Outlet_Years` (the years of operation of a store)\n",
    "\n",
    "\n",
    "#### Before we begin modeling let's do a quick exploration of out new dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#explore the dataset\n",
    "big_mart = pd.read_csv('big_mart_clean.csv')\n",
    "big_mart_orig = pd.read_csv('big_mart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(big_mart.drop(columns=['Item_Sales_Cat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_mart_reg = pd.concat([big_mart.drop(columns=['Item_Sales_Cat']), big_mart_orig['Item_Outlet_Sales']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
       "       'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Size',\n",
       "       'Outlet_Location_Type', 'Outlet_Type', 'Item_Type_Combined',\n",
       "       'Outlet_Years', 'Item_Outlet_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_mart_reg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8523, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_mart_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Item_Identifier', 'Item_Weight', 'Item_Fat_Content', 'Item_Visibility',\n",
       "       'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Size',\n",
       "       'Outlet_Location_Type', 'Outlet_Type', 'Item_Type_Combined',\n",
       "       'Outlet_Years', 'Item_Outlet_Sales'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "big_mart_reg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3735.1380\n",
       "1        443.4228\n",
       "2       2097.2700\n",
       "3        732.3800\n",
       "4        994.7052\n",
       "          ...    \n",
       "8518    2778.3834\n",
       "8519     549.2850\n",
       "8520    1193.1136\n",
       "8521    1845.5976\n",
       "8522     765.6700\n",
       "Name: Item_Outlet_Sales, Length: 8523, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's look at the target variable (Item_Sales_Cat) a little more in depth to examine the classes\n",
    "big_mart_reg.Item_Outlet_Sales\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Modeling\n",
    "\n",
    "Once we have clean data, we can begin modeling! Remember, modeling, as with any of these other steps, is an iterative process. During this stage, we'll try to build and tune models to get the highest performance possible on our task.\n",
    "\n",
    "Consider the following questions during the modeling step:\n",
    "\n",
    "- Is this a classification task? A regression task? Something else?\n",
    "- What models will we try?\n",
    "- How do we deal with overfitting?\n",
    "- Do we need to use regularization or not?\n",
    "- What sort of validation strategy will we be using to check that our model works well on unseen data?\n",
    "- What loss functions will we use?\n",
    "- What threshold of performance do we consider as successful?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation\n",
    "\n",
    "Before we begin modeling let's split our data and then perform encoding/scaling steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set random state for our notebook\n",
    "import numpy as np\n",
    "np.random.seed(217)\n",
    "\n",
    "y = big_mart_reg['Item_Outlet_Sales']\n",
    "X = big_mart_reg.drop(columns=['Item_Outlet_Sales', 'Item_Identifier'])\n",
    "\n",
    "#split data into test and train sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6392, 11), (6392,), (2131, 11), (2131,))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get shape of the training and test sets\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2131x39 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 20879 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Add code here\n",
    "numeric_features = ['Item_Weight', 'Item_Visibility',\n",
    "                     'Item_MRP', 'Outlet_Years']\n",
    "ss=StandardScaler()\n",
    "\n",
    "categorical_features = [ 'Item_Fat_Content',\n",
    "       'Item_Type', 'Outlet_Identifier',\n",
    "       'Outlet_Size', 'Outlet_Location_Type',\n",
    "       'Outlet_Type', 'Item_Type_Combined' ]\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"ordinal\", OrdinalEncoder()),\n",
    "    ('onehot', OneHotEncoder(categories='auto',drop='first'))])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', ss, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)], remainder='passthrough')\n",
    "\n",
    "#let's use it now!\n",
    "\n",
    "X_train_tran = preprocessor.fit_transform(X_train)\n",
    "X_train_tran\n",
    "\n",
    "#and we can transform X_test too\n",
    "\n",
    "X_test_tran = preprocessor.fit_transform(X_test)\n",
    "X_test_tran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Years</th>\n",
       "      <th>Non-Edible</th>\n",
       "      <th>Regular</th>\n",
       "      <th>Breads</th>\n",
       "      <th>Breakfast</th>\n",
       "      <th>Canned</th>\n",
       "      <th>Dairy</th>\n",
       "      <th>...</th>\n",
       "      <th>OUT049</th>\n",
       "      <th>Medium</th>\n",
       "      <th>Small</th>\n",
       "      <th>Tier 2</th>\n",
       "      <th>Tier 3</th>\n",
       "      <th>Supermarket Type1</th>\n",
       "      <th>Supermarket Type2</th>\n",
       "      <th>Supermarket Type3</th>\n",
       "      <th>Food</th>\n",
       "      <th>Non-Consumable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-1.036915</td>\n",
       "      <td>-0.972700</td>\n",
       "      <td>0.824790</td>\n",
       "      <td>-1.341284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-0.378661</td>\n",
       "      <td>-0.223000</td>\n",
       "      <td>-0.764420</td>\n",
       "      <td>-0.148401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.011160</td>\n",
       "      <td>1.071408</td>\n",
       "      <td>-1.309291</td>\n",
       "      <td>1.521635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.933487</td>\n",
       "      <td>-0.723034</td>\n",
       "      <td>0.085657</td>\n",
       "      <td>1.283059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.895380</td>\n",
       "      <td>-0.073697</td>\n",
       "      <td>-1.289446</td>\n",
       "      <td>-1.341284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Weight  Item_Visibility  Item_MRP  Outlet_Years  Non-Edible  Regular  \\\n",
       "0    -1.036915        -0.972700  0.824790     -1.341284         1.0      0.0   \n",
       "1    -0.378661        -0.223000 -0.764420     -0.148401         0.0      1.0   \n",
       "2    -0.011160         1.071408 -1.309291      1.521635         0.0      1.0   \n",
       "3     1.933487        -0.723034  0.085657      1.283059         1.0      0.0   \n",
       "4     0.895380        -0.073697 -1.289446     -1.341284         0.0      1.0   \n",
       "\n",
       "   Breads  Breakfast  Canned  Dairy  ...  OUT049  Medium  Small  Tier 2  \\\n",
       "0     0.0        0.0     0.0    0.0  ...     0.0     1.0    0.0     0.0   \n",
       "1     0.0        0.0     0.0    0.0  ...     1.0     1.0    0.0     0.0   \n",
       "2     0.0        0.0     0.0    0.0  ...     0.0     1.0    0.0     0.0   \n",
       "3     0.0        0.0     0.0    0.0  ...     0.0     0.0    0.0     0.0   \n",
       "4     0.0        0.0     0.0    0.0  ...     0.0     1.0    0.0     0.0   \n",
       "\n",
       "   Tier 3  Supermarket Type1  Supermarket Type2  Supermarket Type3  Food  \\\n",
       "0     1.0                0.0                1.0                0.0   0.0   \n",
       "1     0.0                1.0                0.0                0.0   1.0   \n",
       "2     1.0                0.0                0.0                1.0   1.0   \n",
       "3     1.0                1.0                0.0                0.0   0.0   \n",
       "4     1.0                0.0                1.0                0.0   1.0   \n",
       "\n",
       "   Non-Consumable  \n",
       "0             1.0  \n",
       "1             0.0  \n",
       "2             0.0  \n",
       "3             1.0  \n",
       "4             0.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get column names for categories\n",
    "cat_names = preprocessor.named_transformers_['cat'].named_steps['ordinal'].categories_\n",
    "\n",
    "cat_names = [val for sublist in cat_names for val in sublist[1:]]\n",
    "cat_names\n",
    "\n",
    "#full list of column names\n",
    "column_names = numeric_features + cat_names\n",
    "\n",
    "#apply column names to dataframe\n",
    "X_train_trans = pd.DataFrame.sparse.from_spmatrix(X_train_tran, columns=column_names)\n",
    "X_train_trans.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Model\n",
    "\n",
    "First we are going to start with a dummy model to predict if the product has high or low sales. In our dummy model we classify everything as the majority class.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.390621156440286e+31"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DummyClassifier to predict only target 0\n",
    "dummy = DummyRegressor(strategy='mean')\n",
    "dummy.fit(X_train_tran, y_train)\n",
    "y_hat_train = dummy.predict(X_train_tran)\n",
    "r2_score(y_hat_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two approaches\n",
    "##### Sklearn vs statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evalution\n",
    "\n",
    "During the evaluation step we want to evaluate the results of our models, and decide the next steps in selecting the \"best\" model.  During this step we should consider the following:\n",
    "\n",
    "- Does our model solve the business problem?\n",
    "- What metrics should we be using to evaluate the \"success\" of our model?\n",
    "- Can we further improve our models?\n",
    "- Do we need more data?  Or different data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some helpful code for me later on\n",
    "\n",
    "sns.pairplot(df)b\n",
    "plt.show()\n",
    "fig = sm.qqplot(normal_rv, line = 'r')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
